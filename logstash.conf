input {
  kafka {
    bootstrap_servers => "kafka1:19092"
    topics => ["filebeat-logs"]
    group_id => "logstash-group"
    codec => "json"
    debug => true
    auto_offset_reset => "earliest"
  }
}

filter {
  # Parsing the log message to extract fields
  grok {
    match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:loglevel} %{NUMBER:pid} --- \[%{DATA:thread}\] \[%{GREEDYDATA:container}\] %{GREEDYDATA:class}  : %{GREEDYDATA:log_message}" }
    overwrite => ["message"]
  }

  # Optional: Add additional fields or transformations
  mutate {
    rename => {
      "timestamp" => "@timestamp"
    }
    remove_field => ["log"]
  }
}

output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    user => "elastic"
    password => "123123"
    index => "test"
  }

  stdout { codec => rubydebug }  # Optional: Print to stdout for debugging
}